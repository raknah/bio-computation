{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **6.8701 | 6.8700[J] | HST.507[J]**\n",
        "\n",
        "\n",
        "\n",
        "#**Fall 2024 Problem Set 0**\n",
        "\n",
        "Due: Wednesday September 11 at 11:59 PM EDT\n",
        "\n",
        "Create a copy of this notebook and work on your local copy.\n",
        "\n",
        "Submit .ipynb file as well as PDF to Canvas."
      ],
      "metadata": {
        "id": "fgNUW9Q9ZIVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports/Installation"
      ],
      "metadata": {
        "id": "lr3ciDESWaR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikit-learn scipy pyranges biopython pyjaspar pysam pyfaidx logomaker anndata torch bio requests ##note: scikit-learn was sklearn in a previous version"
      ],
      "metadata": {
        "id": "AfeoCcTNqf3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b90bb0-cb75-47b8-bec9-5e81fbc678cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Collecting pyranges\n",
            "  Downloading pyranges-0.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting biopython\n",
            "  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting pyjaspar\n",
            "  Downloading pyjaspar-3.0.0.tar.gz (51.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pysam\n",
            "  Downloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pyfaidx\n",
            "  Downloading pyfaidx-0.8.1.2-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting logomaker\n",
            "  Downloading logomaker-0.8-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting anndata\n",
            "  Downloading anndata-0.10.9-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Collecting bio\n",
            "  Downloading bio-1.7.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pyranges) (2.1.4)\n",
            "Collecting ncls>=0.0.63 (from pyranges)\n",
            "  Downloading ncls-0.0.68-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pyranges) (0.9.0)\n",
            "Collecting sorted-nearest>=0.0.33 (from pyranges)\n",
            "  Downloading sorted_nearest-0.0.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (964 bytes)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from pyranges) (8.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from pyjaspar) (0.44.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyfaidx) (71.0.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from pyfaidx) (8.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyfaidx) (24.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from logomaker) (3.7.1)\n",
            "Collecting array-api-compat!=1.5,>1.4 (from anndata)\n",
            "  Downloading array_api_compat-1.8-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata) (1.2.2)\n",
            "Requirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from anndata) (3.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting gprofiler-official (from bio)\n",
            "  Downloading gprofiler_official-1.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mygene (from bio)\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from bio) (1.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bio) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pyranges) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pyranges) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pyranges) (2024.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->pyfaidx) (3.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->logomaker) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->logomaker) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->logomaker) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->logomaker) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->logomaker) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->logomaker) (3.1.4)\n",
            "Collecting biothings-client>=0.2.6 (from mygene->bio)\n",
            "  Downloading biothings_client-0.3.1-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->bio) (4.2.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->pyranges) (1.16.0)\n",
            "Downloading pyranges-0.1.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (22.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyfaidx-0.8.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading logomaker-0.8-py2.py3-none-any.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anndata-0.10.9-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bio-1.7.1-py3-none-any.whl (280 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.0/281.0 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading array_api_compat-1.8-py3-none-any.whl (38 kB)\n",
            "Downloading ncls-0.0.68-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sorted_nearest-0.0.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Downloading biothings_client-0.3.1-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: pyjaspar\n",
            "  Building wheel for pyjaspar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjaspar: filename=pyjaspar-3.0.0-py3-none-any.whl size=51125722 sha256=c7772edd7d80415db4b4f3e281366fab5c4944ef6e487b28a9c142d66e6984cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/be/ea/cdfde3a744432366940abfe35bf7efd717bd065a31ef1028c3\n",
            "Successfully built pyjaspar\n",
            "Installing collected packages: array-api-compat, sorted-nearest, pysam, ncls, biopython, pyjaspar, pyfaidx, gprofiler-official, biothings-client, pyranges, mygene, logomaker, anndata, bio\n",
            "Successfully installed anndata-0.10.9 array-api-compat-1.8 bio-1.7.1 biopython-1.84 biothings-client-0.3.1 gprofiler-official-1.0.0 logomaker-0.8 mygene-3.2.2 ncls-0.0.68 pyfaidx-0.8.1.2 pyjaspar-3.0.0 pyranges-0.1.2 pysam-0.22.1 sorted-nearest-0.0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import requests\n",
        "from io import StringIO\n",
        "from Bio import SeqIO\n",
        "from Bio import Entrez"
      ],
      "metadata": {
        "id": "JC7n4zjEsCCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.1 Basic Tensor Problems**\n",
        "\n",
        "What are Tensors?\n",
        "\n",
        "Tensors are a generalization of vectors and matrices to potentially higher dimensions. In computational biology, you often work with data that come in various forms and dimensions:\n",
        "\n",
        "Scalars (0D tensors): A single number, like the pH value of a solution.\n",
        "Vectors (1D tensors): An array of numbers, which might represent gene expression levels across a set of genes.\n",
        "Matrices (2D tensors): A 2-dimensional array, common for representing images in microscopy or data tables where rows and columns correspond to samples and features, respectively.\n",
        "As we extend to more dimensions, we encounter tensors:\n",
        "\n",
        "3D Tensors: Often used for time-series data where each matrix slice represents data at a different time point.\n",
        "\n",
        "4D Tensors: Common in more complex imaging data, such as MRI scans, where each 3D tensor in the stack might represent a different scan sequence or condition."
      ],
      "metadata": {
        "id": "MvdwG_rtqmSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, write a function that generates a n by n tensor with random numbers, normalizes it, and calculates statitics, using Pytorch."
      ],
      "metadata": {
        "id": "rB3J-7q39GgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Q1.1\n",
        "def analyze_2d_tensor(n):\n",
        "    \"\"\"\n",
        "    Creates a 2-dimensional tensor of size n x n filled with random numbers, normalizes it,\n",
        "    and prints the mean, minimum, and maximum values of the normalized tensor.\n",
        "\n",
        "    Steps:\n",
        "    1. Create a 2D tensor of size 3x3 with random numbers.\n",
        "    2. Normalize this tensor so that the sum of all elements is 1.\n",
        "    3. Calculate and print the mean, minimum, and maximum values of the normalized tensor.\n",
        "\n",
        "    Returns:\n",
        "    n by n tensor that sums to 1.\n",
        "\n",
        "    Hint: https://pytorch.org/docs/stable/generated/torch.rand.html\n",
        "    \"\"\"\n",
        "    # your code here:\n",
        "    pass"
      ],
      "metadata": {
        "id": "TAwEi_4R8CHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Datatype\n",
        "Datatypes in tensors specify the kind of elements stored (e.g., integers, floating-points). They affect the tensor's memory usage and computational precision. Common types include:\n",
        "\n",
        "torch.float: Used for decimal numbers in computations.\n",
        "torch.int: Used for integers, like indices or counts.\n",
        "torch.bool: Used for true/false conditions.\n",
        "Correct datatypes ensure efficient and error-free operations in computations.\n",
        "\n",
        "## Memory Residency: CPU vs. GPU\n",
        "Tensors can be stored on the CPU or GPU:\n",
        "\n",
        "CPU Memory: Default storage, versatile but slower for large-scale operations.\n",
        "GPU Memory: Used for high-speed parallel computations. Essential for accelerating deep learning tasks, requires explicit management (moving tensors to GPU).\n",
        "Understanding where a tensor resides (CPU or GPU) is crucial for optimizing the performance of computational tasks."
      ],
      "metadata": {
        "id": "KBAc1jgX9bjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Q1.2\n",
        "def print_tensor_properties(tensor):\n",
        "  \"\"\"\n",
        "  This function outputs the 1) shape, 2) data type, and 3) device location of a tensor.\n",
        "  It helps in debugging and understanding tensor attributes in computational graphs.\n",
        "\n",
        "  Parameters:\n",
        "  tensor (Tensor): The tensor object whose properties are to be printed.\n",
        "\n",
        "  Returns:\n",
        "  None\n",
        "\n",
        "  Hint: please read about tensor attributes at https://pytorch.org/docs/stable/tensor_attributes.html\n",
        "  \"\"\"\n",
        "  pass"
      ],
      "metadata": {
        "id": "l-y_J1WX9KQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Tensor Operations: Indexing and Slicing"
      ],
      "metadata": {
        "id": "6jfkhpWV-_c8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing and Slicing\n",
        "Indexing and slicing are powerful tools that enable you to access and modify specific parts of tensors, which are the fundamental data structures in libraries like PyTorch used for machine learning and scientific computing.\n",
        "\n",
        "### Indexing\n",
        "Tensor indexing allows you to access individual elements or sequences of elements from a tensor. This is similar to accessing elements of a list or array in traditional programming languages. In PyTorch, indexing is zero-based, meaning the first element is indexed with zero. You can use both positive and negative indices (where negative indices start counting from the end of the tensor).\n",
        "\n",
        "### Slicing\n",
        "Slicing, on the other hand, refers to accessing a contiguous region of a tensor. This lets you retrieve or modify portions of the tensor, such as rows, columns, or higher-dimensional slices. The basic syntax for slicing uses the colon : operator, which allows you to specify the start, stop, and step of the slice, much like slicing in Python lists or numpy arrays.\n",
        "\n",
        "### Syntax Overview:\n",
        "\n",
        "tensor[start\n",
        "]: Extracts a portion of the tensor from the 'start' index to 'stop-1' index.\n",
        "tensor[start:stop\n",
        "]: Extracts elements from 'start' to 'stop-1' with a step size of 'step'.\n",
        "tensor[:, n]: Extracts the nth column across all dimensions (2D case).\n",
        "tensor[n, :]: Extracts the nth row across all dimensions (2D case).\n",
        "\n",
        "Below, we will explore several exercises where you'll apply indexing and slicing to perform data manipulation tasks. Each function comes with a docstring detailing specific objectives; your task is to implement the code that meets these requirements."
      ],
      "metadata": {
        "id": "hgglIuk-AY0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.3\n",
        "def extract_submatrix(tensor):\n",
        "    \"\"\"\n",
        "    Extract the middle submatrix of a square tensor.\n",
        "\n",
        "    This function takes a square tensor and extracts a submatrix from its center.\n",
        "    If the input tensor is of size n x n, the function extracts the (n-2) x (n-2) center submatrix.\n",
        "\n",
        "    Parameters:\n",
        "    tensor (torch.Tensor): A square tensor from which the submatrix will be extracted.\n",
        "    Assume the tnesor is at least 3x3.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: A submatrix extracted from the center of the input tensor. The size of the\n",
        "    returned tensor is (n-2) x (n-2) if the original tensor is n x n.\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "hn5uY0bB_BNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.4\n",
        "def extract_diagonal(tensor):\n",
        "    \"\"\"\n",
        "    Extract the diagonal elements from a square tensor using indexing or multiplication.\n",
        "\n",
        "    Implement this function by choosing one of the following methods:\n",
        "    1. (prefered) Indexing: Directly select the diagonal elements using tensor indexing.\n",
        "    2. Multiplication: Use a mask (identity matrix) to multiply the tensor element-wise,\n",
        "       isolating the diagonal elements and then collapsing the matrix to extract them.\n",
        "\n",
        "    Do not use torch.diag(tensor)\n",
        "\n",
        "    Parameters:\n",
        "    tensor (torch.Tensor): A square tensor from which the diagonal elements will be extracted.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: A 1D tensor containing the diagonal elements of the input tensor.\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "-ynhn9iFBP2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.5\n",
        "def select_elements():\n",
        "    \"\"\"\n",
        "    Create a 6x6 matrix with random integers and selects elements that are located\n",
        "    in even rows and odd columns.\n",
        "\n",
        "    The even row is defined as a row with an even index (0-based), and the odd column\n",
        "    is defined as a column with an odd index (0-based).\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: A tensor containing the selected elements.\n",
        "\n",
        "    This problem is more difficut than 1.3 and 1.4. Please post on Piazza if you\n",
        "    need help.\n",
        "    \"\"\"\n",
        "    pass  # Student to implement this function"
      ],
      "metadata": {
        "id": "NabcBQQ9j5z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intermediate Problems"
      ],
      "metadata": {
        "id": "Siw6L4TsQtO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When manipluating tensors, common operations are to transpose, reshape, and broadcast.\n",
        "\n",
        "**Transpose** adjusts tensor dimensions, essential for matching matrix operations' requirements in algorithms, particularly in neural networks where data orientation affects performance.\n",
        "\n",
        "**Reshape** modifies tensor dimensions without altering its data, facilitating the adaptation of structures for specific operations, crucial for efficient data processing across different layers.\n",
        "\n",
        "**Broadcast** allows for operations between tensors of different shapes by automatically aligning dimensions, enhancing computational efficiency and reducing memory use, critical for large-scale data manipulations.\n",
        "\n",
        "Below are three exercises to practise these operations. Please visit https://pytorch.org/docs/stable/tensors.html for documentation.\n",
        "\n",
        "Implement code that meets the requirements in the docstrings."
      ],
      "metadata": {
        "id": "tT2PmumIcmbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.6\n",
        "def create_and_transpose_tensor():\n",
        "    \"\"\"\n",
        "   Create a 3D tensor of shape (3, 4, 5) with elements ranging from 0 to 59 (sequential integers),\n",
        "   and transpose it to the shape (5, 4, 3). Return the transposed tensor.\n",
        "\n",
        "  Returns:\n",
        "  torch.Tensor: The transposed tensor of shape (5, 4, 3).\n",
        "  \"\"\"\n",
        "  pass  # Student to implement this function"
      ],
      "metadata": {
        "id": "eWfEgy-eQxDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.7\n",
        "def reshape_tensors():\n",
        "    \"\"\"\n",
        "    Creates two tensors and reshapes them:\n",
        "    1. A tensor of random numbers with shape (8, 2), reshaped to (4, 4).\n",
        "    2. A tensor 't' of shape (64,) containing values from 1 to 64,\n",
        "       reshaped first to (8, 8) and then to (2, 16, 2).\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the reshaped tensors.\n",
        "    \"\"\"\n",
        "    pass  # Student to implement this function"
      ],
      "metadata": {
        "id": "qSE8FJZ9Q0z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.8\n",
        "def perform_broadcasting():\n",
        "    \"\"\"\n",
        "    Demonstrates broadcasting with two examples:\n",
        "    1. Initialize an arbitrary tensor of shape (5, 5) and a tensor of shape (5, 1),\n",
        "    then add them.\n",
        "    2. What happens when trying to add tensors of shapes (5, 1, 4) and (3, 1)?\n",
        "\n",
        "    Write a comment explaining broadcasting and the results of the two above operations.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the result of the first addition and a string explanation\n",
        "           of what happens in the second case.\n",
        "    \"\"\"\n",
        "    pass  # Student to implement this function"
      ],
      "metadata": {
        "id": "AwMhAEIcQ29X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Problems\n"
      ],
      "metadata": {
        "id": "j7ZZ9PfQQ6Zs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boolean indexing is a powerful technique that allows for direct manipulation of tensor elements based on conditional statements, which can be particularly useful for modifying datasets in-situ. In this problem, a 10x10 tensor filled with random integers is created, and elements within a specified range in a particular row are set to zero. In 1.8, you will use Boolean indexing selectively zero elements in a particular row."
      ],
      "metadata": {
        "id": "rP_FqVv3glZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.9\n",
        "def zero_elements():\n",
        "    \"\"\"\n",
        "    Create a 10x10 tensor with random integers and use boolean indexing to set elements\n",
        "    in the range [3, 7) in the 5th row to zero.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: The modified tensor after applying boolean indexing.\n",
        "    \"\"\"\n",
        "    pass  # Student to implement this function"
      ],
      "metadata": {
        "id": "6m0qyrzdNRpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you'll explore matrix operations in PyTorch by implementing batch matrix multiplication. Instead of using the dedicated torch.bmm() function, you'll use torch.matmul(), a versatile function designed for multi-dimensional matrix multiplication. Your goal is to replicate the functionality of torch.bmm() with torch.matmul()"
      ],
      "metadata": {
        "id": "3Y6RzfE1pZYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.10\n",
        "def batch_matrix_multiplication(batch_A=torch.arange(10*3*4).reshape(10, 3, 4), batch_B=torch.arange(10*4*5).reshape(10, 4, 5)):\n",
        "    \"\"\"\n",
        "    Performs batch matrix multiplication between two batches of matrices.\n",
        "\n",
        "    Use torch.matmul() to reimplement torch.bmm().\n",
        "\n",
        "    Parameters:\n",
        "    batch_A (torch.Tensor): A tensor of shape (10, 3, 4) representing the first batch of matrices.\n",
        "    batch_B (torch.Tensor): A tensor of shape (10, 4, 5) representing the second batch of matrices.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: A tensor of shape (10, 3, 5) resulting from the batch matrix multiplication of batch_A and batch_B.\n",
        "    \"\"\"\n",
        "    pass  # Student to implement this function"
      ],
      "metadata": {
        "id": "xrF3fIUJacRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradients and Differentiation"
      ],
      "metadata": {
        "id": "Mr7aOlG4ak6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "PyTorch is a powerful tool primarily because of its dynamic computation graph and automatic differentiation system, which simplify the process of building and training complex neural network models. Pytorch's autograd system automatically calculates gradients—a fundamental operation required for training most types of machine learning models. This feature allows developers and researchers to define models in a straightforward way, using normal Pythonic constructs, and then rely on PyTorch to handle the complexities of differentiation.\n",
        "\n",
        "Here, we"
      ],
      "metadata": {
        "id": "MaK5_OmRrri_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.10\n",
        "def compute_gradient(x=None, y=None):\n",
        "    \"\"\"\n",
        "    Computes the gradient of the expression z = x * x + y * y with respect to tensors x and y.\n",
        "\n",
        "    Initialize tensors x and y within the function.\n",
        "    x and y should be tensors of size (5,) with `requires_grad` set to True.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the gradients dz/dx and dz/dy.\n",
        "\n",
        "    Please initialize x and y in the function using torch.tensor with requires_grad=True.\n",
        "    Read https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html to\n",
        "    understand how to use .backward() to compute gradients.\n",
        "    \"\"\"\n",
        "    pass  # Student to implement this function"
      ],
      "metadata": {
        "id": "O92ib5PGamui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Biopython Exercises"
      ],
      "metadata": {
        "id": "PvPSGXLZIaqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Set for Learning the Basics of Biopython\n",
        "\n",
        "Before starting this section, familiarize yourself with the basics of Biopython at:\n",
        "https://biopython.org/DIST/docs/tutorial/Tutorial.html\n",
        "\n",
        "Biopython is a powerful library designed for biological computation, providing tools and classes for various bioinformatics tasks. It enables efficient manipulation of genetic sequences, including reading and writing multiple sequence formats, calculating key statistics like GC content, and generating sequence features such as reverse complements. The library includes objects that represent biological entities in meaningful ways, facilitating easy and effective data manipulations and analyses.\n",
        "\n",
        "To work on Q2.1 and Q2.2, read https://biopython.org/wiki/Seq before writing a function that achieves the objectives outlined."
      ],
      "metadata": {
        "id": "nSydo9WZI2E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.1\n",
        "def analyze_dna_sequence(seq_string=\"ATGCGTACGTTAGCC\"):\n",
        "    \"\"\"\n",
        "    Analyzes a given DNA sequence by printing the sequence, computing its GC content,\n",
        "    and printing its reverse complement.\n",
        "\n",
        "    Please use the the 'Seq' object from Biopython's Bio.Seq module to represent the DNA sequence,\n",
        "    allowing for effective manipulation and analysis of the sequence data.\n",
        "\n",
        "    Parameters:\n",
        "    seq_string (str): The DNA sequence string to analyze, defaulting to \"ATGCGTACGTTAGCC\".\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing:\n",
        "           - float: The GC content of the sequence as a percentage.\n",
        "           - str: The reverse complement of the sequence.\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "1UlwT0DLIfWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.2\n",
        "def process_dna_sequence(dna_seq=\"ATGCGTACGTTAGCC\"):\n",
        "    \"\"\"\n",
        "    Transcribes a DNA sequence into mRNA, translates that mRNA into an amino acid sequence,\n",
        "    and prints all sequences for comparison.\n",
        "\n",
        "    Transcription involves converting DNA into mRNA, where 'T' (thymine) is replaced by 'U' (uracil).\n",
        "    Translation converts mRNA into a sequence of amino acids, forming a protein.\n",
        "\n",
        "    Parameters:\n",
        "    dna_seq (Bio.Seq.Seq): A DNA sequence object.\n",
        "\n",
        "    Outputs:\n",
        "    Prints the original DNA sequence, the transcribed mRNA sequence, and the translated protein sequence.\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "qFcLNSbWMIaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with NCBI and FASTA files"
      ],
      "metadata": {
        "id": "-6kMm33OXWb4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this exercise, you'll be dealing with downloading and processing sequence data from the web, a common task in bioinformatics when working with genomic data.\n",
        "\n",
        "In bioinformatics, FASTA format is widely used to represent nucleotide or peptide sequences. The SeqIO module in Biopython provides essential tools for reading and writing sequences in various formats, including FASTA. In the exercise, the code for downloading a FASTA file is written. Your goal is to create a new FASTA file but with reverse complements of the original sequences."
      ],
      "metadata": {
        "id": "M6EfpEs4yZOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_process_fasta(url='https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id=NC_012920&db=nuccore&report=fasta'):\n",
        "    \"\"\"\n",
        "    Downloads a FASTA file from a URL and processes each entry to print details and keep sequences in memory.\n",
        "\n",
        "    Parameters:\n",
        "    url (str): The URL to download the FASTA file from.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of sequence records, each with IDs and reverse complements.\n",
        "\n",
        "    Write the sequences to a new FASTA file, but with all the sequences converted to their reverse complements.\n",
        "    \"\"\"\n",
        "    # Download the FASTA file and parse it\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure the download was successful\n",
        "    fasta_io = StringIO(response.text)\n",
        "    records = list(SeqIO.parse(fasta_io, \"fasta\"))\n",
        "\n",
        "# URL to the NCBI entry for the human mitochondrial genome\n",
        "url = 'https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id=NC_012920&db=nuccore&report=fasta'\n",
        "fasta_records = download_and_process_fasta(url)\n",
        "\n",
        "# Optionally, you might want to print or further analyze the results\n",
        "# for record in fasta_records:\n",
        "#    print(record['ID'], \"Reverse Complement Length:\", len(record['Reverse Complement']))"
      ],
      "metadata": {
        "id": "aLGjQbpuMKP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ec2d2c-baaf-43ab-d55d-30f55e92c716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SeqRecord(seq=Seq('GATCACAGGTCTATCACCCTATTAACCACTCACGGGAGCTCTCCATGCATTTGG...ATG'), id='NC_012920.1', name='NC_012920.1', description='NC_012920.1 Homo sapiens mitochondrion, complete genome', dbxrefs=[])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrez is a data retrieval system that offers access to a diverse set of databases from the National Center for Biotechnology Information (NCBI). In this exercise, you'll learn to interact with the Entrez system using Biopython's Entrez module. This involves searching for and downloading specific nucleotide sequence data using a gene accession number, which is a unique identifier for a specific version of a sequence record.\n",
        "\n",
        "Use Entrez.efetch to find nucelotide sequence data for gene ascension number \"NM_001200025\". Then print out the description and sequence."
      ],
      "metadata": {
        "id": "cJhZMpT-zfrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_and_parse_sequence(accession_number):\n",
        "    \"\"\"\n",
        "    Uses the Entrez module to search for and download nucleotide sequence data for a given gene accession number.\n",
        "    Parses the downloaded data to print the description and sequence.\n",
        "\n",
        "    Parameters:\n",
        "    accession_number (str): The accession number of the gene for which sequence data is to be retrieved.\n",
        "\n",
        "    Notes:\n",
        "    Make sure to provide your email address to NCBI using Entrez.email to use NCBI's E-utilities.\n",
        "    Make use of the SeqIO package to read the retrieved FASTA\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "# Example usage\n",
        "fetch_and_parse_sequence(\"NM_001200025\")"
      ],
      "metadata": {
        "id": "ljfrbCJt4HvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequence Alignment"
      ],
      "metadata": {
        "id": "A8OhnflwW4MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairwise sequence alignment is a critical technique in bioinformatics, used to compare two biological sequences (DNA, RNA, or proteins) to identify regions of similarity. These alignments help infer homology, guide sequence annotations, and are integral to tasks such as gene identification and phylogenetic analysis. In this exercise, you will use Biopython’s alignment tools to perform and analyze the alignment between two given sequences."
      ],
      "metadata": {
        "id": "HEfcCSyn1pNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_pairwise_alignment(seq1=\"ACTGCTAGCTAG\", seq2=\"GCTAGCTGATCG\"):\n",
        "    \"\"\"\n",
        "    Performs a pairwise alignment between two sequences and prints the alignments along with their scores.\n",
        "\n",
        "    Parameters:\n",
        "    seq1 (str): The first sequence to align. Default is \"ACTGCTAGCTAG\".\n",
        "    seq2 (str): The second sequence to align. Default is \"GCTAGCTGATCG\".\n",
        "\n",
        "    Any substitution matrix and gap penalty is allowed.\n",
        "\n",
        "    Output:\n",
        "    Prints each alignment and its score.\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "HGdGUwj16PTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with Features and Annotations:\n",
        "\n",
        "For this task, you'll delve into working with genomic annotations by manipulating data from a GenBank file. This exercise focuses on the human mitochondria genome, and involves extracting names, locations, and making an annotation of the genomic length."
      ],
      "metadata": {
        "id": "YgNHi5jOWP9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_genbank_features(accession_number=\"NC_012920\"):\n",
        "    \"\"\"\n",
        "    Processes a GenBank file by retrieving and modifying genomic annotations. This function focuses on the human mitochondria genome or a bacteriophage,\n",
        "    using the provided accession number to fetch the data. Students will extract gene names and their locations, and then annotate each gene with its genomic length.\n",
        "\n",
        "    Steps:\n",
        "    1. Fetch the GenBank file using the given accession number.\n",
        "    2. Iterate over the 'gene' features within the GenBank file.\n",
        "    3. For each gene, print its name and location.\n",
        "    4. Calculate and print the genomic length for each gene based on its location.\n",
        "    5. Create a new annotation for each gene to include its genomic length.\n",
        "\n",
        "    Parameters:\n",
        "    accession_number (str): The accession number of the GenBank file to be processed.\n",
        "\n",
        "    Note: This function requires that an email address be set for NCBI E-utilities usage,\n",
        "    which should be properly configured before running the function.\n",
        "\n",
        "    Hints:\n",
        "    - `feature.qualifiers`: This is a dictionary available for each feature in a GenBank file,\n",
        "    where each key represents a type of annotation (like gene name) and the associated value is a list of details pertaining to that annotation.\n",
        "    - Genomic length can be calculated using the `len()` function on the `feature.location` object,\n",
        "    which gives you the length of the gene in base pairs.\n",
        "    - Adding a new annotation involves adding a new key-value pair to the `feature.qualifiers` dictionary.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "process_genbank_features(\"NC_012920\")"
      ],
      "metadata": {
        "id": "Zknmh0CsWPH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}